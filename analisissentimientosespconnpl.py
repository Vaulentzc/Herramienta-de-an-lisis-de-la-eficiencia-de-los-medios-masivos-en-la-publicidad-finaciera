# -*- coding: utf-8 -*-
"""AnalisisSentimientosESPconNPL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ewksJzsDSRdMmOhMaO3m64FlYvFF7ms8
"""

#Esto es un programa de analisis de sentimientos en español
!pip install textblob spacy vaderSentiment nltk wordcloud matplotlib
!python -m textblob.download_corpora
!python -m spacy download es_core_news_sm

#Importar las librerias
import re
import unicodedata
import spacy
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import matplotlib.pyplot as plt
from wordcloud import WordCloud

#load file
from google.colab import files
uploaded = files.upload()

#Get the data from the file
#store the csv file to some variable
df = pd.read_csv('sentiment_data.csv')
print(df.head())

# Seleccionar solo la columna de texto y eliminar filas vacías
df = df[['texto']].dropna()

# Función para limpiar el texto
def clean_text(text):
    text = str(text)  # Asegurar que sea string
    text = re.sub(r'@[A-Za-z0-9]+', '', text)  # Eliminar menciones
    text = re.sub(r'#', '', text)  # Eliminar hashtags
    text = re.sub(r'RT[\s]+', '', text)  # Eliminar RT
    text = re.sub(r'https?://\S+|www\.\S+', '', text)  # Eliminar URLs
    text = re.sub(r'[^\w\s]', '', text)  # Eliminar signos de puntuación
    text = text.lower()  # Convertir a minúsculas
    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')  # Quitar acentos
    return text

# Aplicar limpieza a la columna de texto
df['Cleaned_Text'] = df['texto'].apply(clean_text)

# Cargar modelo en español de spaCy
nlp = spacy.load('es_core_news_sm')
analyzer = SentimentIntensityAnalyzer()

#funcion para determinar la polaridad
def get_polarity(text):
    return TextBlob(text).sentiment.polarity

#funcion para determinar la subjetividad
def get_subjectivity(text):
    return TextBlob(text).sentiment.subjectivity

# Aplicar análisis de sentimientos
def get_sentiment(text):
    text = ' '.join([token.lemma_ for token in nlp(text)])  # Lematización
    score = analyzer.polarity_scores(text)['compound']
    if score < 0:
        return 'Negativo'
    elif score == 0:
        return 'Neutral'
    else:
        return 'Positivo'

print(df.columns)

df['Polarity'] = df['Cleaned_Text'].apply(get_polarity)
df['Subjectivity'] = df['Cleaned_Text'].apply(get_subjectivity)
df['Sentiment'] = df['Cleaned_Text'].apply(get_sentiment)

# Mostrar los primeros resultados del analisis de sentimientos
print(df.head())

# Generar una nube de palabras
all_words = ' '.join(df['Cleaned_Text'])
wordcloud = WordCloud(width=500, height=300, random_state=21, max_font_size=110).generate(all_words)

plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

# Graficar distribución de análisis de sentimientos
df['Sentiment'].value_counts().plot(kind='bar', color=['red', 'blue', 'green'])
plt.title('Análisis de Sentimientos')
plt.xlabel('Sentimiento')
plt.ylabel('Cantidad')
plt.show()

#Print all of the negative tweets
j=1
sortedDF = df.sort_values(by = ['Polarity'], ascending='Faslse')
for i in range(0, sortedDF.shape[0]):
  if (sortedDF['Analysis'][i] == 'negative'):
    print(str(j) + ') ' + sortedDF['Tweets'][i])
    print()
    j=j+1

#plot the polarity and subjectivity
plt.figure(figsize=(8,6))
for i in range(0, df.shape[0]):
  plt.scatter(df['polarity'][i], df['subjectivity'][i], color='Blue')

  plt.title('Sentiment Analisys')
  plt.xlabel('polarity')
  plt.ylabel('subjectivity')
  plt.show

#Get the porcentage of positive tweets
ptweets=df[df.Analysis == 'positive']
ptweets=ptweets['Tweets']
round( ()ptweets.shape[0] / df.shape[0]*100 , 1)

#Get the porcentage of negative tweets
ntweets=df[df.Analysis == 'negative']
ntweets=ntweets['Tweets']
round( ()ntweets.shape[0] / df.shape[0]*100 , 1)

#Show thw value counts

df['Analysis'].value_counts()

#plot and visualize the counts
plt.title('Sentiment Analisys')
plt.xlabel('sentiment')
plt.ylabel('counts')

df['Analysis'].value_counts().plot(kind='bar')
plt.show